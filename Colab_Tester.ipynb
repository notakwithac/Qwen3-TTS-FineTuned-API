{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Qwen3-TTS API Service â€” Colab Tester\n",
                "\n",
                "This notebook allows you to test the Fine-Tuning API on Google Colab GPUs (T4, L4, or A100).\n",
                "\n",
                "### 1. Setup Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!git clone https://github.com/your-repo/Qwen-Finetune.git\n",
                "%cd Qwen-Finetune/Qwen3-TTS\n",
                "\n",
                "# Install dependencies (Colab has torch/transformers pre-installed usually, but we need others)\n",
                "!pip install -v -e .\n",
                "!pip install fastapi uvicorn python-multipart boto3 soundfile librosa torchaudio accelerate huggingface_hub\n",
                "\n",
                "# Pre-download models to avoid timeouts during API calls\n",
                "!python download_models.py"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Set Credentials\n",
                "Replace these with your E2E Object Storage credentials if you want to test S3 uploads."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "os.environ[\"E2E_ACCESS_KEY\"] = \"your_access_key\"\n",
                "os.environ[\"E2E_SECRET_KEY\"] = \"your_secret_key\"\n",
                "os.environ[\"E2E_BUCKET\"] = \"qwen3-tts\"\n",
                "os.environ[\"GPU_IDLE_TIMEOUT\"] = \"300\" # 5 minutes"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Start API Service with Tunnel\n",
                "We use `localtunnel` to expose the API running inside the Colab VM."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install localtunnel\n",
                "!npm install -g localtunnel\n",
                "\n",
                "# Start the API in the background\n",
                "import subprocess\n",
                "subprocess.Popen([\"uvicorn\", \"api_server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"])\n",
                "\n",
                "# Connect the tunnel\n",
                "!lt --port 8000"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Run Smoke Test\n",
                "While the API is running, you can open another cell or a local terminal and run `test_api.py` against the tunnel URL."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}